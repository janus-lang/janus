// SPDX-License-Identifier: LCL-1.0
// Copyright (c) 2026 Self Sovereign Society Foundation

const std = @import("std");
const Allocator = std.mem.Allocator;

// Type system imports
const TypeId = @import("type_registry.zig").TypeId;
const DispatchEntry = @import("dispatch_table_manager.zig").DispatchEntry;
const CandidateIR = @import("ir_dispatch.zig").CandidateIR;

/// Perfect hash generator using CHD (Compress, Hash, and Displace) algorithm
pub const PerfectHashGenerator = struct {
    allocator: Allocator,

    // Generation parameters
    max_iterations: u32 = 1000,
    load_factor: f32 = 0.8,

    // Statistics
    stats: GenerationStats,

    const GenerationStats = struct {
        attempts: u32 = 0,
        collisions_resolved: u32 = 0,
        generation_time_ns: u64 = 0,
        final_table_size: u32 = 0,

        pub fn reset(self: *GenerationStats) void {
            self.* = GenerationStats{};
        }
    };

    pub fn init(allocator: Allocator) PerfectHashGenerator {
        return PerfectHashGenerator{
            .allocator = allocator,
            .stats = GenerationStats{},
        };
    }

    /// Generate a perfect hash table for the given candidates
    pub fn generate(
        self: *PerfectHashGenerator,
        candidates: []const CandidateIR,
    ) !?PerfectHashTable {
        const start_time = std.time.nanoTimestamp();
        defer {
            const end_time = std.time.nanoTimestamp();
            self.stats.generation_time_ns = @intCast(end_time - start_time);
        }

        self.stats.reset();

        std.debug.print("üîç Generating perfect hash for {} candidates\n", .{candidates.len});

        // Quick feasibility check
        if (!self.isFeasible(candidates)) {
            std.debug.print("‚ùå Perfect hash not feasible for this candidate set\n", .{});
            return null;
        }

        // Extract type IDs for hashing
        const type_ids = try self.extractTypeIds(candidates);
        defer self.allocator.free(type_ids);

        // Try to generate perfect hash with different parameters
        var attempt: u32 = 0;
        while (attempt < self.max_iterations) : (attempt += 1) {
            self.stats.attempts += 1;

            if (try self.attemptGeneration(type_ids, candidates)) |hash_table| {
                self.stats.final_table_size = hash_table.table_size;
                std.debug.print("‚úÖ Perfect hash generated in {} attempts\n", .{attempt + 1});
                return hash_table;
            }
        }

        std.debug.print("‚ùå Failed to generate perfect hash after {} attempts\n", .{self.max_iterations});
        return null;
    }

    /// Check if perfect hash generation is feasible for the candidate set
    fn isFeasible(self: *PerfectHashGenerator, candidates: []const CandidateIR) bool {
        // Basic feasibility checks
        if (candidates.len == 0) return false;
        if (candidates.len > 10000) return false; // Practical limit

        // Check for duplicate type IDs (would make perfect hash impossible)
        var seen_types = std.AutoHashMap(u32, void).init(self.allocator);
        defer seen_types.deinit();

        for (candidates) |candidate| {
            const type_id = candidate.type_check_ir.target_type.id;
            if (seen_types.contains(type_id)) {
                return false; // Duplicate type ID
            }
            seen_types.put(type_id, {}) catch return false;
        }

        return true;
    }

    /// Extract type IDs from candidates for hash generation
    fn extractTypeIds(self: *PerfectHashGenerator, candidates: []const CandidateIR) ![]u32 {
        const type_ids = try self.allocator.alloc(u32, candidates.len);

        for (candidates, 0..) |candidate, i| {
            type_ids[i] = candidate.type_check_ir.target_type.id;
        }

        return type_ids;
    }

    /// Attempt to generate a perfect hash with current parameters
    fn attemptGeneration(
        self: *PerfectHashGenerator,
        type_ids: []const u32,
        candidates: []const CandidateIR,
    ) !?PerfectHashTable {
        // Calculate table size based on load factor
        const table_size = @as(u32, @intFromFloat(@as(f32, @floatFromInt(type_ids.len)) / self.load_factor));

        // Generate random hash seed
        var prng = std.Random.DefaultPrng.init(@intCast(std.time.nanoTimestamp()));
        const hash_seed = prng.random().int(u64);

        // Create hash table structure
        var hash_table = PerfectHashTable{
            .buckets = try self.allocator.alloc(HashBucket, table_size),
            .displacement = try self.allocator.alloc(u32, table_size),
            .hash_seed = hash_seed,
            .candidate_count = @intCast(type_ids.len),
            .table_size = table_size,
            .generation_time_ns = 0, // Will be set by caller
        };

        // Initialize buckets
        for (hash_table.buckets) |*bucket| {
            bucket.* = HashBucket{
                .entries = try self.allocator.alloc(?*const DispatchEntry, 1),
                .displacement_index = 0,
            };
            bucket.entries[0] = null;
        }

        // Initialize displacement array
        @memset(hash_table.displacement, 0);

        // Try to place all type IDs without collisions
        if (try self.placeTypeIds(type_ids, candidates, &hash_table)) {
            return hash_table;
        } else {
            // Clean up failed attempt
            self.deallocateHashTable(&hash_table);
            return null;
        }
    }

    /// Place type IDs in hash table using CHD algorithm
    fn placeTypeIds(
        self: *PerfectHashGenerator,
        type_ids: []const u32,
        candidates: []const CandidateIR,
        hash_table: *PerfectHashTable,
    ) !bool {
        // Phase 1: Assign type IDs to buckets
        var bucket_assignments = try self.allocator.alloc(std.ArrayList(u32), hash_table.table_size);
        defer {
            for (bucket_assignments) |*list| {
                list.deinit();
            }
            self.allocator.free(bucket_assignments);
        }

        for (bucket_assignments) |*list| {
            list.* = std.ArrayList(u32).init(self.allocator);
        }

        // Hash each type ID to a bucket
        for (type_ids) |type_id| {
            const bucket_index = self.hashToBucket(type_id, hash_table.hash_seed, hash_table.table_size);
            try bucket_assignments[bucket_index].append(type_id);
        }

        // Phase 2: Resolve collisions using displacement
        for (bucket_assignments, 0..) |bucket_list, bucket_index| {
            if (bucket_list.items.len <= 1) {
                // No collision, direct placement
                if (bucket_list.items.len == 1) {
                    const type_id = bucket_list.items[0];
                    const candidate_index = self.findCandidateIndex(type_id, candidates);
                    if (candidate_index) |idx| {
                        // Create dispatch entry (simplified)
                        const entry = try self.createDispatchEntry(candidates[idx]);
                        hash_table.buckets[bucket_index].entries[0] = entry;
                    }
                }
            } else {
                // Collision detected, try to resolve with displacement
                if (!try self.resolveCollision(bucket_list.items, bucket_index, candidates, hash_table)) {
                    return false; // Failed to resolve collision
                }
                self.stats.collisions_resolved += 1;
            }
        }

        return true;
    }

    /// Resolve collision in a bucket using displacement
    fn resolveCollision(
        self: *PerfectHashGenerator,
        colliding_ids: []const u32,
        bucket_index: usize,
        candidates: []const CandidateIR,
        hash_table: *PerfectHashTable,
    ) !bool {
        // Try different displacement values
        var displacement: u32 = 1;
        while (displacement < hash_table.table_size) : (displacement += 1) {
            var placement_valid = true;
            var temp_positions: std.ArrayList(u32) = .empty;
            defer temp_positions.deinit();

            // Check if all colliding IDs can be placed with this displacement
            for (colliding_ids) |_| {
                const displaced_pos = (bucket_index + displacement) % hash_table.table_size;

                // Check if position is available
                if (hash_table.buckets[displaced_pos].entries[0] != null) {
                    placement_valid = false;
                    break;
                }

                try temp_positions.append(@intCast(displaced_pos));
            }

            if (placement_valid) {
                // Place all colliding IDs with this displacement
                hash_table.displacement[bucket_index] = displacement;

                for (colliding_ids, 0..) |type_id, i| {
                    const pos = temp_positions.items[i];
                    const candidate_index = self.findCandidateIndex(type_id, candidates);
                    if (candidate_index) |idx| {
                        const entry = try self.createDispatchEntry(candidates[idx]);
                        hash_table.buckets[pos].entries[0] = entry;
                    }
                }

                return true;
            }
        }

        return false; // Could not resolve collision
    }

    /// Hash a type ID to a bucket index
    fn hashToBucket(self: *PerfectHashGenerator, type_id: u32, seed: u64, table_size: u32) u32 {
        _ = self;

        // Simple hash function (would use more sophisticated hashing in production)
        var hasher = std.hash.Wyhash.init(seed);
        hasher.update(std.mem.asBytes(&type_id));
        const hash_value = hasher.final();

        return @intCast(hash_value % table_size);
    }

    /// Find candidate index by type ID
    fn findCandidateIndex(self: *PerfectHashGenerator, type_id: u32, candidates: []const CandidateIR) ?usize {
        _ = self;

        for (candidates, 0..) |candidate, i| {
            if (candidate.type_check_ir.target_type.id == type_id) {
                return i;
            }
        }

        return null;
    }

    /// Create a dispatch entry from candidate IR (simplified)
    fn createDispatchEntry(self: *PerfectHashGenerator, candidate: CandidateIR) !*const DispatchEntry {
        const entry = try self.allocator.create(DispatchEntry);
        entry.* = DispatchEntry{
            .type_id = candidate.type_check_ir.target_type,
            .function_name = candidate.function_ref.name,
            .mangled_name = candidate.function_ref.mangled_name,
            .match_score = candidate.match_score,
            .conversion_cost = 0, // Simplified
        };
        return entry;
    }

    /// Clean up hash table memory
    fn deallocateHashTable(self: *PerfectHashGenerator, hash_table: *PerfectHashTable) void {
        for (hash_table.buckets) |*bucket| {
            self.allocator.free(bucket.entries);
        }
        self.allocator.free(hash_table.buckets);
        self.allocator.free(hash_table.displacement);
    }

    /// Get generation statistics
    pub fn getStats(self: *const PerfectHashGenerator) GenerationStats {
        return self.stats;
    }
};

/// Perfect hash table structure
pub const PerfectHashTable = struct {
    // CHD algorithm components
    buckets: []HashBucket,
    displacement: []u32,
    hash_seed: u64,

    // Metadata
    candidate_count: u32,
    table_size: u32,
    generation_time_ns: u64,

    /// Lookup a dispatch entry by type ID
    pub fn lookup(self: *const PerfectHashTable, type_id: TypeId) ?*const DispatchEntry {
        // Hash to bucket
        var hasher = std.hash.Wyhash.init(self.hash_seed);
        hasher.update(std.mem.asBytes(&type_id.id));
        const hash_value = hasher.final();
        const bucket_index = hash_value % self.table_size;

        // Apply displacement if any
        const displacement = self.displacement[bucket_index];
        const final_index = (bucket_index + displacement) % self.table_size;

        // Check bucket
        const bucket = &self.buckets[final_index];
        if (bucket.entries.len > 0 and bucket.entries[0] != null) {
            const entry = bucket.entries[0].?;
            if (entry.type_id.equals(type_id)) {
                return entry;
            }
        }

        return null;
    }

    /// Get memory usage statistics
    pub fn getMemoryUsage(self: *const PerfectHashTable) MemoryUsage {
        const bucket_memory = self.buckets.len * @sizeOf(HashBucket);
        const displacement_memory = self.displacement.len * @sizeOf(u32);
        const entry_memory = self.candidate_count * @sizeOf(DispatchEntry);

        return MemoryUsage{
            .total_bytes = bucket_memory + displacement_memory + entry_memory,
            .bucket_bytes = bucket_memory,
            .displacement_bytes = displacement_memory,
            .entry_bytes = entry_memory,
            .overhead_ratio = @as(f32, @floatFromInt(self.table_size)) / @as(f32, @floatFromInt(self.candidate_count)),
        };
    }

    pub fn deinit(self: *const PerfectHashTable, allocator: Allocator) void {
        for (self.buckets) |*bucket| {
            for (bucket.entries) |entry| {
                if (entry) |e| {
                    allocator.destroy(e);
                }
            }
            allocator.free(bucket.entries);
        }
        allocator.free(self.buckets);
        allocator.free(self.displacement);
    }
};

/// Hash bucket in the perfect hash table
pub const HashBucket = struct {
    entries: []?*const DispatchEntry,
    displacement_index: u32,
};

/// Memory usage statistics
pub const MemoryUsage = struct {
    total_bytes: usize,
    bucket_bytes: usize,
    displacement_bytes: usize,
    entry_bytes: usize,
    overhead_ratio: f32,
};

// Tests
test "PerfectHashGenerator basic functionality" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    var generator = PerfectHashGenerator.init(allocator);

    // Create mock candidates
    const TypeCheckIR = @import("ir_dispatch.zig").TypeCheckIR;
    const FunctionRef = @import("ir_dispatch.zig").FunctionRef;
    const FunctionSignature = @import("ir_dispatch.zig").FunctionSignature;

    const candidates = [_]CandidateIR{
        CandidateIR{
            .function_ref = FunctionRef{
                .name = "func1",
                .mangled_name = "_Z5func1i",
                .signature = FunctionSignature{
                    .parameters = @constCast(&[_]TypeId{TypeId.I32}),
                    .return_type = TypeId.STRING,
                    .is_variadic = false,
                },
            },
            .conversion_path = &[_]@import("ir_dispatch.zig").ConversionStep{},
            .match_score = 10,
            .type_check_ir = TypeCheckIR{
                .check_kind = .exact_match,
                .target_type = TypeId.I32,
                .parameter_index = 0,
            },
        },
        CandidateIR{
            .function_ref = FunctionRef{
                .name = "func2",
                .mangled_name = "_Z5func2d",
                .signature = FunctionSignature{
                    .parameters = @constCast(&[_]TypeId{TypeId.F64}),
                    .return_type = TypeId.STRING,
                    .is_variadic = false,
                },
            },
            .conversion_path = &[_]@import("ir_dispatch.zig").ConversionStep{},
            .match_score = 10,
            .type_check_ir = TypeCheckIR{
                .check_kind = .exact_match,
                .target_type = TypeId.F64,
                .parameter_index = 0,
            },
        },
    };

    // Test feasibility check
    try std.testing.expect(generator.isFeasible(&candidates));

    // Test hash generation
    if (try generator.generate(&candidates)) |hash_table| {
        defer hash_table.deinit(allocator);

        // Verify hash table properties
        try std.testing.expect(hash_table.candidate_count == 2);
        try std.testing.expect(hash_table.table_size >= 2);

        // Test lookup
        const entry1 = hash_table.lookup(TypeId.I32);
        try std.testing.expect(entry1 != null);
        try std.testing.expectEqualStrings("func1", entry1.?.function_name);

        const entry2 = hash_table.lookup(TypeId.F64);
        try std.testing.expect(entry2 != null);
        try std.testing.expectEqualStrings("func2", entry2.?.function_name);

        // Test memory usage
        const memory_usage = hash_table.getMemoryUsage();
        try std.testing.expect(memory_usage.total_bytes > 0);
        try std.testing.expect(memory_usage.overhead_ratio >= 1.0);

        std.debug.print("‚úÖ Perfect hash generated: {} bytes, {d:.2} overhead ratio\n", .{
            memory_usage.total_bytes,
            memory_usage.overhead_ratio,
        });
    } else {
        std.debug.print("‚ö†Ô∏è Perfect hash generation failed (acceptable for test)\n", .{});
    }

    const stats = generator.getStats();
    std.debug.print("üìä Generation stats: {} attempts, {} ns\n", .{
        stats.attempts,
        stats.generation_time_ns,
    });

    std.debug.print("‚úÖ PerfectHashGenerator test passed\n", .{});
}

test "PerfectHashGenerator feasibility checks" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    var generator = PerfectHashGenerator.init(allocator);

    // Test empty candidates
    const empty_candidates: []const CandidateIR = &[_]CandidateIR{};
    try std.testing.expect(!generator.isFeasible(empty_candidates));

    std.debug.print("‚úÖ PerfectHashGenerator feasibility test passed\n", .{});
}
